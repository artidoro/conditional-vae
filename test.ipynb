{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "% load_ext autoreload\n",
    "% autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import train\n",
    "import cvae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter, val_iter, test, DE, EN = utils.torchtext_extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"test\"\n",
    "\n",
    "gpu = True\n",
    "\n",
    "num_layers = 2\n",
    "embed_size = 100\n",
    "hidden_size = 100\n",
    "latent_size = 20\n",
    "\n",
    "num_epochs=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/artidoro/.local/lib/python3.5/site-packages/torch/backends/cudnn/__init__.py:84: UserWarning: PyTorch was compiled without cuDNN support. To use cuDNN, rebuild PyTorch making sure the library is visible to the build system.\n",
      "  \"PyTorch was compiled without cuDNN support. To use cuDNN, rebuild \"\n"
     ]
    }
   ],
   "source": [
    "model = cvae.CVAE(len(DE.vocab), len(EN.vocab), embed_size, hidden_size, latent_size, num_layers)\n",
    "if gpu:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/3722 [00:00<?, ?it/s]\u001b[A/home/artidoro/.local/lib/python3.5/site-packages/torch/backends/cudnn/__init__.py:84: UserWarning: PyTorch was compiled without cuDNN support. To use cuDNN, rebuild PyTorch making sure the library is visible to the build system.\n",
      "  \"PyTorch was compiled without cuDNN support. To use cuDNN, rebuild \"\n",
      "\n",
      "  0%|          | 1/3722 [00:01<1:08:47,  1.11s/it]\u001b[A\n",
      "  0%|          | 3/3722 [00:01<26:44,  2.32it/s]  \u001b[A\n",
      "  0%|          | 5/3722 [00:01<18:02,  3.43it/s]\u001b[A\n",
      "  0%|          | 7/3722 [00:01<14:31,  4.26it/s]\u001b[A\n",
      "  0%|          | 9/3722 [00:01<12:15,  5.05it/s]\u001b[A\n",
      "  0%|          | 11/3722 [00:01<10:45,  5.75it/s]\u001b[A\n",
      "  0%|          | 13/3722 [00:02<09:49,  6.30it/s]\u001b[A\n",
      "  0%|          | 15/3722 [00:02<09:08,  6.75it/s]\u001b[A\n",
      "  0%|          | 17/3722 [00:02<08:35,  7.18it/s]\u001b[A\n",
      "  1%|          | 19/3722 [00:02<08:07,  7.60it/s]\u001b[A\n",
      "  1%|          | 21/3722 [00:02<07:43,  7.99it/s]\u001b[A\n",
      "  1%|          | 23/3722 [00:02<07:25,  8.31it/s]\u001b[A\n",
      "  1%|          | 25/3722 [00:02<07:10,  8.59it/s]\u001b[A\n",
      "  1%|          | 27/3722 [00:03<06:59,  8.81it/s]\u001b[A\n",
      "  1%|          | 30/3722 [00:03<06:37,  9.28it/s]\u001b[A\n",
      "  1%|          | 32/3722 [00:03<06:25,  9.56it/s]\u001b[A\n",
      "  1%|          | 34/3722 [00:03<06:17,  9.76it/s]\u001b[A\n",
      "  1%|          | 36/3722 [00:03<06:11,  9.91it/s]\u001b[A\n",
      "  1%|          | 39/3722 [00:03<05:57, 10.30it/s]\u001b[A\n",
      "  1%|          | 41/3722 [00:03<05:53, 10.42it/s]\u001b[A\n",
      "  1%|          | 43/3722 [00:04<05:46, 10.62it/s]\u001b[A\n",
      "  1%|          | 45/3722 [00:04<05:41, 10.78it/s]\u001b[A\n",
      "  1%|▏         | 47/3722 [00:04<05:36, 10.92it/s]\u001b[A\n",
      "  1%|▏         | 49/3722 [00:04<05:32, 11.05it/s]\u001b[A\n",
      "  1%|▏         | 51/3722 [00:04<05:28, 11.18it/s]\u001b[A\n",
      "  1%|▏         | 53/3722 [00:04<05:26, 11.24it/s]\u001b[A\n",
      "  1%|▏         | 55/3722 [00:04<05:23, 11.33it/s]\u001b[A\n",
      "  2%|▏         | 58/3722 [00:05<05:17, 11.55it/s]\u001b[A\n",
      "  2%|▏         | 60/3722 [00:05<05:13, 11.66it/s]\u001b[A\n",
      "  2%|▏         | 62/3722 [00:05<05:10, 11.77it/s]\u001b[A\n",
      "  2%|▏         | 64/3722 [00:05<05:09, 11.82it/s]\u001b[A\n",
      "  2%|▏         | 66/3722 [00:05<05:06, 11.94it/s]\u001b[A\n",
      "  2%|▏         | 68/3722 [00:05<05:04, 11.99it/s]\u001b[A\n",
      "  2%|▏         | 71/3722 [00:05<04:59, 12.20it/s]\u001b[A\n",
      "  2%|▏         | 73/3722 [00:05<04:57, 12.28it/s]\u001b[A\n",
      "  2%|▏         | 75/3722 [00:06<04:54, 12.39it/s]\u001b[A\n",
      "  2%|▏         | 77/3722 [00:06<04:52, 12.48it/s]\u001b[A\n",
      "  2%|▏         | 79/3722 [00:06<04:50, 12.52it/s]\u001b[A\n",
      "  2%|▏         | 81/3722 [00:06<04:50, 12.54it/s]\u001b[A\n",
      "  2%|▏         | 83/3722 [00:06<04:49, 12.58it/s]\u001b[A\n",
      "  2%|▏         | 86/3722 [00:06<04:45, 12.74it/s]\u001b[A\n",
      "  2%|▏         | 88/3722 [00:06<04:43, 12.83it/s]\u001b[A\n",
      "  2%|▏         | 90/3722 [00:07<04:42, 12.84it/s]\u001b[A\n",
      "  2%|▏         | 92/3722 [00:07<04:41, 12.90it/s]\u001b[A\n",
      "  3%|▎         | 94/3722 [00:07<04:39, 12.96it/s]\u001b[A\n",
      "  3%|▎         | 96/3722 [00:07<04:37, 13.05it/s]\u001b[A\n",
      "  3%|▎         | 98/3722 [00:07<04:36, 13.12it/s]\u001b[A\n",
      "  3%|▎         | 100/3722 [00:07<04:34, 13.19it/s]\u001b[A\n",
      "  3%|▎         | 102/3722 [00:07<04:34, 13.20it/s]\u001b[A\n",
      "  3%|▎         | 104/3722 [00:07<04:32, 13.26it/s]\u001b[A\n",
      "  3%|▎         | 106/3722 [00:07<04:32, 13.28it/s]\u001b[A\n",
      "  3%|▎         | 108/3722 [00:08<04:30, 13.34it/s]\u001b[A\n",
      "  3%|▎         | 110/3722 [00:08<04:29, 13.40it/s]\u001b[A\n",
      "  3%|▎         | 112/3722 [00:08<04:29, 13.42it/s]\u001b[A\n",
      "  3%|▎         | 114/3722 [00:08<04:28, 13.45it/s]\u001b[A\n",
      "  3%|▎         | 116/3722 [00:08<04:27, 13.49it/s]\u001b[A\n",
      "  3%|▎         | 118/3722 [00:08<04:27, 13.48it/s]\u001b[A\n",
      "  3%|▎         | 120/3722 [00:08<04:26, 13.53it/s]\u001b[A\n",
      "  3%|▎         | 122/3722 [00:08<04:24, 13.59it/s]\u001b[A\n",
      "  3%|▎         | 124/3722 [00:09<04:24, 13.61it/s]\u001b[A\n",
      "  3%|▎         | 126/3722 [00:09<04:24, 13.61it/s]\u001b[A\n",
      "  3%|▎         | 128/3722 [00:09<04:22, 13.67it/s]\u001b[A\n",
      "  3%|▎         | 130/3722 [00:09<04:21, 13.72it/s]\u001b[A\n",
      "  4%|▎         | 132/3722 [00:09<04:21, 13.71it/s]\u001b[A\n",
      "  4%|▎         | 134/3722 [00:09<04:21, 13.72it/s]\u001b[A\n",
      "  4%|▎         | 136/3722 [00:09<04:20, 13.75it/s]\u001b[A\n",
      "Exception in thread Thread-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/threading.py\", line 914, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tqdm/_tqdm.py\", line 144, in run\n",
      "    for instance in self.tqdm_cls._instances:\n",
      "  File \"/usr/lib/python3.5/_weakrefset.py\", line 60, in __iter__\n",
      "    for itemref in self.data:\n",
      "RuntimeError: Set changed size during iteration\n",
      "\n",
      "100%|██████████| 3722/3722 [03:57<00:00, 15.70it/s]\n",
      "  0%|          | 0/18 [00:00<?, ?it/s]/usr/local/lib/python3.5/dist-packages/torchtext/data/field.py:321: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  return Variable(arr, volatile=not train)\n",
      "100%|██████████| 18/18 [00:00<00:00, 51.07it/s]\n",
      "  0%|          | 0/3722 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 ValPerpBound: 167.2720 NLLBound: 64.5816 RE: 64.5547 KL: 0.0269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 1447/3722 [01:32<02:24, 15.72it/s]"
     ]
    }
   ],
   "source": [
    "train.train(model, model_name, train_iter, val_iter, DE, EN, num_epochs, gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "val_perp = utils.perp_bound(model, val_iter, gpu)\n",
    "print(val_perp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EN.vocab.stoi['</s>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 1])\n"
     ]
    }
   ],
   "source": [
    "import beam_search\n",
    "import torch\n",
    "k = 10\n",
    "bos = EN.vocab.stoi['<s>']\n",
    "eos = EN.vocab.stoi['</s>']\n",
    "max_len = 20\n",
    "    \n",
    "for batch in train_iter:\n",
    "    if gpu:\n",
    "        src = batch.src.cuda()\n",
    "    else:\n",
    "        src = batch.src\n",
    "    break\n",
    "\n",
    "\n",
    "src = src[:,:1].contiguous()\n",
    "print(src.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = src.cuda()\n",
    "print(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beam_search.beam_search(k, max_len, model, src, bos, eos, gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if gpu: \n",
    "    src = src.cuda()\n",
    "\n",
    "# run encoder\n",
    "encoded_src = model.encode(src) # batch size = 1\n",
    "\n",
    "# init \n",
    "init_prob = -1e10\n",
    "best_options = [(init_prob, [bos], None)] # beam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for length in range(max_len): # maximum target length\n",
    "    options = [] # candidates \n",
    "\n",
    "    for lprob, sentence, hidden in best_options:\n",
    "        # Prepare last word\n",
    "        last_word = sentence[-1]\n",
    "\n",
    "        # keep sentences ending in '</s>' as candidates\n",
    "        if last_word == eos:\n",
    "            options.append((lprob, sentence, current_state))\n",
    "\n",
    "        else:\n",
    "            last_word_input = torch.tensor([last_word], requires_grad=False).long().view(1,1)\n",
    "            if gpu: last_word_input = last_word_input.cuda()\n",
    "\n",
    "            # Decode\n",
    "            lprobs, new_hidden = model.generate(last_word_input, encoded_src, hidden)\n",
    "            # Add top k candidates to options list for next word\n",
    "\n",
    "    lprobs = lprobs.squeeze()\n",
    "    for index in torch.topk(lprobs, k)[1]:         \n",
    "        option = (lprobs[index].item() + lprob, sentence + [index], new_hidden) \n",
    "        options.append(option)\n",
    "\n",
    "    options.sort(key = lambda x: x[0], reverse=True) # sort by lprob\n",
    "    best_options = options[:k] # place top candidates in beam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lprob: -10000000718.4467 sentence: \n",
      " <s> compassion relatively eating leaf We innovate : account maybe gifted them put gave . manage accessories or dream compassion see join your think dream story reader picked affect manage this . The closet compassion : your , compassion righting drive shaping Russia Paper join see created . pieces policy . compassion manage pieces figure reader can product account , this The adversity . so I That Russia trip innovate figure dream policy The Russia see , your give created <pad> \n",
      "lprob: -10000000718.9462 sentence: \n",
      " <s> compassion relatively eating leaf We innovate : account maybe gifted them put gave . manage accessories or dream compassion see join your think dream story reader picked affect manage this . The closet compassion : your , compassion righting drive shaping Russia Paper join see created . pieces policy . compassion manage pieces figure reader can product account , this The adversity . so I That Russia trip innovate figure dream policy The Russia see , your give created regions \n",
      "lprob: -10000000718.9619 sentence: \n",
      " <s> compassion relatively eating leaf We innovate : account maybe gifted them put gave . manage accessories or dream compassion see join your think dream story reader picked affect manage this . The closet compassion : your , compassion righting drive shaping Russia Paper join see created . pieces policy . compassion manage pieces figure reader can product account , this The adversity . so I That Russia trip innovate figure dream policy The Russia see , your give created account \n",
      "lprob: -10000000718.9927 sentence: \n",
      " <s> compassion relatively eating leaf We innovate : account maybe gifted them put gave . manage accessories or dream compassion see join your think dream story reader picked affect manage this . The closet compassion : your , compassion righting drive shaping Russia Paper join see created . pieces policy . compassion manage pieces figure reader can product account , this The adversity . so I That Russia trip innovate figure dream policy The Russia see , your give created compassion \n",
      "lprob: -10000000719.0160 sentence: \n",
      " <s> compassion relatively eating leaf We innovate : account maybe gifted them put gave . manage accessories or dream compassion see join your think dream story reader picked affect manage this . The closet compassion : your , compassion righting drive shaping Russia Paper join see created . pieces policy . compassion manage pieces figure reader can product account , this The adversity . so I That Russia trip innovate figure dream policy The Russia see , your give created the \n",
      "lprob: -10000000719.0177 sentence: \n",
      " <s> compassion relatively eating leaf We innovate : account maybe gifted them put gave . manage accessories or dream compassion see join your think dream story reader picked affect manage this . The closet compassion : your , compassion righting drive shaping Russia Paper join see created . pieces policy . compassion manage pieces figure reader can product account , this The adversity . so I That Russia trip innovate figure dream policy The Russia see , your give created n't \n",
      "lprob: -10000000719.0232 sentence: \n",
      " <s> compassion relatively eating leaf We innovate : account maybe gifted them put gave . manage accessories or dream compassion see join your think dream story reader picked affect manage this . The closet compassion : your , compassion righting drive shaping Russia Paper join see created . pieces policy . compassion manage pieces figure reader can product account , this The adversity . so I That Russia trip innovate figure dream policy The Russia see , your give created created \n",
      "lprob: -10000000719.0283 sentence: \n",
      " <s> compassion relatively eating leaf We innovate : account maybe gifted them put gave . manage accessories or dream compassion see join your think dream story reader picked affect manage this . The closet compassion : your , compassion righting drive shaping Russia Paper join see created . pieces policy . compassion manage pieces figure reader can product account , this The adversity . so I That Russia trip innovate figure dream policy The Russia see , your give created think \n",
      "lprob: -10000000719.0283 sentence: \n",
      " <s> compassion relatively eating leaf We innovate : account maybe gifted them put gave . manage accessories or dream compassion see join your think dream story reader picked affect manage this . The closet compassion : your , compassion righting drive shaping Russia Paper join see created . pieces policy . compassion manage pieces figure reader can product account , this The adversity . so I That Russia trip innovate figure dream policy The Russia see , your give created The \n",
      "lprob: -10000000719.0311 sentence: \n",
      " <s> compassion relatively eating leaf We innovate : account maybe gifted them put gave . manage accessories or dream compassion see join your think dream story reader picked affect manage this . The closet compassion : your , compassion righting drive shaping Russia Paper join see created . pieces policy . compassion manage pieces figure reader can product account , this The adversity . so I That Russia trip innovate figure dream policy The Russia see , your give created react \n"
     ]
    }
   ],
   "source": [
    "for lprob, sentence, _ in best_options:\n",
    "    string = \"\"\n",
    "    for s in sentence:\n",
    "        string += EN.vocab.itos[s] + \" \"\n",
    "    print(\"lprob: {:.4f} sentence: \\n {}\".format(lprob, string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = [\"hello\", \"my\", \"name\", \"is\"]\n",
    "l2 = [\"hello\", \"my\", \"as\", \"ad\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6389431042462724\n",
      "0.4999999950000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/artidoro/.local/lib/python3.5/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 3-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "print(utils.bleu(l1, l2))\n",
    "print(utils.rouge(l1, l2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
